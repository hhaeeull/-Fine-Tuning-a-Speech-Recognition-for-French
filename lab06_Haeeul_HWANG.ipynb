{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%pip install datasets==1.18.3\n",
    "%pip install transformers==4.11.3\n",
    "%pip install librosa\n",
    "%pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the tsv file using pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('metadata_lab_m2li.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "      <th>clip</th>\n",
       "      <th>duration[ms]</th>\n",
       "      <th>total_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>898da828246ce49a58def510072044db74eaae191a47b0...</td>\n",
       "      <td>common_voice_fr_25026726.mp3</td>\n",
       "      <td>Parmi eux, une petite fille, Rosina, qui le fr...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français du Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_25026726.mp3</td>\n",
       "      <td>6084</td>\n",
       "      <td>6084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>898da828246ce49a58def510072044db74eaae191a47b0...</td>\n",
       "      <td>common_voice_fr_25026727.mp3</td>\n",
       "      <td>Vingt à trente mètres sous le sommet, un abri ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français du Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_25026727.mp3</td>\n",
       "      <td>6444</td>\n",
       "      <td>12528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>898da828246ce49a58def510072044db74eaae191a47b0...</td>\n",
       "      <td>common_voice_fr_25026728.mp3</td>\n",
       "      <td>Le sac et la corde aux comédiens et au cardinal!</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français du Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_25026728.mp3</td>\n",
       "      <td>4644</td>\n",
       "      <td>17172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>898da828246ce49a58def510072044db74eaae191a47b0...</td>\n",
       "      <td>common_voice_fr_25026730.mp3</td>\n",
       "      <td>Il parle couramment l'anglais et il a une bonn...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français du Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_25026730.mp3</td>\n",
       "      <td>5940</td>\n",
       "      <td>23112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>898da828246ce49a58def510072044db74eaae191a47b0...</td>\n",
       "      <td>common_voice_fr_25026731.mp3</td>\n",
       "      <td>Le bilan de compétence est avant tout celui du...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français du Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_25026731.mp3</td>\n",
       "      <td>4572</td>\n",
       "      <td>27684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           client_id  \\\n",
       "0  898da828246ce49a58def510072044db74eaae191a47b0...   \n",
       "1  898da828246ce49a58def510072044db74eaae191a47b0...   \n",
       "2  898da828246ce49a58def510072044db74eaae191a47b0...   \n",
       "3  898da828246ce49a58def510072044db74eaae191a47b0...   \n",
       "4  898da828246ce49a58def510072044db74eaae191a47b0...   \n",
       "\n",
       "                           path  \\\n",
       "0  common_voice_fr_25026726.mp3   \n",
       "1  common_voice_fr_25026727.mp3   \n",
       "2  common_voice_fr_25026728.mp3   \n",
       "3  common_voice_fr_25026730.mp3   \n",
       "4  common_voice_fr_25026731.mp3   \n",
       "\n",
       "                                            sentence  up_votes  down_votes  \\\n",
       "0  Parmi eux, une petite fille, Rosina, qui le fr...         2           0   \n",
       "1  Vingt à trente mètres sous le sommet, un abri ...         2           1   \n",
       "2   Le sac et la corde aux comédiens et au cardinal!         2           0   \n",
       "3  Il parle couramment l'anglais et il a une bonn...         2           0   \n",
       "4  Le bilan de compétence est avant tout celui du...         2           0   \n",
       "\n",
       "        age gender             accents  variant locale  segment  \\\n",
       "0  thirties   male  Français du Canada      NaN     fr      NaN   \n",
       "1  thirties   male  Français du Canada      NaN     fr      NaN   \n",
       "2  thirties   male  Français du Canada      NaN     fr      NaN   \n",
       "3  thirties   male  Français du Canada      NaN     fr      NaN   \n",
       "4  thirties   male  Français du Canada      NaN     fr      NaN   \n",
       "\n",
       "                           clip  duration[ms]  total_duration  \n",
       "0  common_voice_fr_25026726.mp3          6084            6084  \n",
       "1  common_voice_fr_25026727.mp3          6444           12528  \n",
       "2  common_voice_fr_25026728.mp3          4644           17172  \n",
       "3  common_voice_fr_25026730.mp3          5940           23112  \n",
       "4  common_voice_fr_25026731.mp3          4572           27684  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio files count: 300\n"
     ]
    }
   ],
   "source": [
    "# list the audio files in the common_voice_audio folder (only the first 300)\n",
    "\n",
    "import os\n",
    "\n",
    "common_voice_audio = os.listdir('common_voice_audio')[:300]\n",
    "\n",
    "print(\"audio files count:\", len(common_voice_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accents</th>\n",
       "      <th>variant</th>\n",
       "      <th>locale</th>\n",
       "      <th>segment</th>\n",
       "      <th>clip</th>\n",
       "      <th>duration[ms]</th>\n",
       "      <th>total_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8b1e91be96d7650e5980595ff9b0ec78d37a0d1d536d45...</td>\n",
       "      <td>common_voice_fr_17315927.mp3</td>\n",
       "      <td>Je trouve à ces amendements un intérêt pédagog...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français de France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_17315927.mp3</td>\n",
       "      <td>4224</td>\n",
       "      <td>39756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9539722ce060eab153f0adb1d5f9e54945322231f04212...</td>\n",
       "      <td>common_voice_fr_23981049.mp3</td>\n",
       "      <td>L'éducation est l'un des objectifs principaux ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_23981049.mp3</td>\n",
       "      <td>4224</td>\n",
       "      <td>168204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>a7181395cba9f9970eff97afa54eb435d12eb8234999d5...</td>\n",
       "      <td>common_voice_fr_19608157.mp3</td>\n",
       "      <td>Le titre olympique revient au Sud-Coréen Jin J...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>thirties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français de France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_19608157.mp3</td>\n",
       "      <td>5376</td>\n",
       "      <td>219540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>affd924b9637cac14b2357d1b192fe2da4d8edf6414a55...</td>\n",
       "      <td>common_voice_fr_18048560.mp3</td>\n",
       "      <td>Travailler jusqu’à deux heures me semblerait s...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français de France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_18048560.mp3</td>\n",
       "      <td>5904</td>\n",
       "      <td>323808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>affd924b9637cac14b2357d1b192fe2da4d8edf6414a55...</td>\n",
       "      <td>common_voice_fr_18048561.mp3</td>\n",
       "      <td>Des mises en réserve pour le sous-objectif soi...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>twenties</td>\n",
       "      <td>male</td>\n",
       "      <td>Français de France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>common_voice_fr_18048561.mp3</td>\n",
       "      <td>6264</td>\n",
       "      <td>330072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            client_id  \\\n",
       "6   8b1e91be96d7650e5980595ff9b0ec78d37a0d1d536d45...   \n",
       "36  9539722ce060eab153f0adb1d5f9e54945322231f04212...   \n",
       "56  a7181395cba9f9970eff97afa54eb435d12eb8234999d5...   \n",
       "78  affd924b9637cac14b2357d1b192fe2da4d8edf6414a55...   \n",
       "79  affd924b9637cac14b2357d1b192fe2da4d8edf6414a55...   \n",
       "\n",
       "                            path  \\\n",
       "6   common_voice_fr_17315927.mp3   \n",
       "36  common_voice_fr_23981049.mp3   \n",
       "56  common_voice_fr_19608157.mp3   \n",
       "78  common_voice_fr_18048560.mp3   \n",
       "79  common_voice_fr_18048561.mp3   \n",
       "\n",
       "                                             sentence  up_votes  down_votes  \\\n",
       "6   Je trouve à ces amendements un intérêt pédagog...         3           0   \n",
       "36  L'éducation est l'un des objectifs principaux ...         2           0   \n",
       "56  Le titre olympique revient au Sud-Coréen Jin J...         2           1   \n",
       "78  Travailler jusqu’à deux heures me semblerait s...         2           0   \n",
       "79  Des mises en réserve pour le sous-objectif soi...         2           0   \n",
       "\n",
       "         age gender             accents  variant locale  segment  \\\n",
       "6   thirties   male  Français de France      NaN     fr      NaN   \n",
       "36  twenties   male                 NaN      NaN     fr      NaN   \n",
       "56  thirties   male  Français de France      NaN     fr      NaN   \n",
       "78  twenties   male  Français de France      NaN     fr      NaN   \n",
       "79  twenties   male  Français de France      NaN     fr      NaN   \n",
       "\n",
       "                            clip  duration[ms]  total_duration  \n",
       "6   common_voice_fr_17315927.mp3          4224           39756  \n",
       "36  common_voice_fr_23981049.mp3          4224          168204  \n",
       "56  common_voice_fr_19608157.mp3          5376          219540  \n",
       "78  common_voice_fr_18048560.mp3          5904          323808  \n",
       "79  common_voice_fr_18048561.mp3          6264          330072  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only the rows with the path corresponding to the extracted files\n",
    "\n",
    "df = df[df['path'].isin(common_voice_audio)]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcriptions\n",
    "\n",
    "transcriptions = list(df['sentence'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Je trouve à ces amendements un intérêt pédagogique.',\n",
       " \"L'éducation est l'un des objectifs principaux du zoo.\",\n",
       " 'Le titre olympique revient au Sud-Coréen Jin Jong-oh.',\n",
       " 'Travailler jusqu’à deux heures me semblerait susceptible de faire consensus.',\n",
       " 'Des mises en réserve pour le sous-objectif soins de ville peuvent être décidées ou non.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all of the characters that are not in the alphabet and not in the french alphabet\n",
    "# lowercase all of the characters\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_special_characters(transcription):\n",
    "    transcription = transcription.lower()\n",
    "    transcription = re.sub(r'[^a-zA-Zàâäçèéêëîïôœùûüÿ\\'\\’\\s]', '', transcription)\n",
    "    transcription = re.sub('-', ' ', transcription)\n",
    "    return transcription\n",
    "\n",
    "transcriptions = [remove_special_characters(transcription) for transcription in transcriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['je trouve à ces amendements un intérêt pédagogique',\n",
       " \"l'éducation est l'un des objectifs principaux du zoo\",\n",
       " 'le titre olympique revient au sudcoréen jin jongoh',\n",
       " 'travailler jusqu’à deux heures me semblerait susceptible de faire consensus',\n",
       " 'des mises en réserve pour le sousobjectif soins de ville peuvent être décidées ou non']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the dataframe\n",
    "\n",
    "df['sentence'] = transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ï': 0,\n",
       " 'ê': 1,\n",
       " 'x': 2,\n",
       " 'b': 3,\n",
       " 'm': 4,\n",
       " 'k': 5,\n",
       " 'ç': 6,\n",
       " 'f': 7,\n",
       " 't': 8,\n",
       " \"'\": 9,\n",
       " 'h': 10,\n",
       " 'â': 11,\n",
       " 'è': 12,\n",
       " 'î': 13,\n",
       " 'c': 14,\n",
       " 'i': 15,\n",
       " 'y': 16,\n",
       " 'ô': 17,\n",
       " 'v': 18,\n",
       " 'w': 19,\n",
       " 'é': 20,\n",
       " 'à': 21,\n",
       " 'o': 22,\n",
       " 'a': 23,\n",
       " 'd': 24,\n",
       " 'r': 25,\n",
       " 'l': 26,\n",
       " 'n': 27,\n",
       " 'j': 28,\n",
       " ' ': 29,\n",
       " 'u': 30,\n",
       " 's': 31,\n",
       " 'z': 32,\n",
       " 'œ': 33,\n",
       " '’': 34,\n",
       " 'g': 35,\n",
       " 'ü': 36,\n",
       " 'e': 37,\n",
       " 'ù': 38,\n",
       " 'p': 39,\n",
       " 'û': 40,\n",
       " 'q': 41}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab\n",
    "\n",
    "vocab_list = list(set(' '.join(transcriptions)))\n",
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "\n",
    "vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the vocab\n",
    "\n",
    "import json\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "# load the tokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "# load the feature extractor\n",
    "# the feature extractor is responsible for processing the audio files\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "# load the processor\n",
    "# the processor is responsible for processing the transcriptions\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./common_voice_audio/common_voice_fr_17315927.mp3',\n",
       "  './common_voice_audio/common_voice_fr_23981049.mp3',\n",
       "  './common_voice_audio/common_voice_fr_19608157.mp3',\n",
       "  './common_voice_audio/common_voice_fr_18048560.mp3',\n",
       "  './common_voice_audio/common_voice_fr_18048561.mp3'],\n",
       " ['je trouve à ces amendements un intérêt pédagogique',\n",
       "  \"l'éducation est l'un des objectifs principaux du zoo\",\n",
       "  'le titre olympique revient au sudcoréen jin jongoh',\n",
       "  'travailler jusqu’à deux heures me semblerait susceptible de faire consensus',\n",
       "  'des mises en réserve pour le sousobjectif soins de ville peuvent être décidées ou non'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio files paths\n",
    "\n",
    "audio_paths = list(df['path'].apply(lambda x: f\"./common_voice_audio/{x}\").values)\n",
    "transcriptions_paths = list(df['sentence'].values)\n",
    "\n",
    "audio_paths[:5], transcriptions_paths[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the arrays of the audio files and the transcriptions using the processor\n",
    "\n",
    "import torch\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech_array = []\n",
    "    for path in batch:\n",
    "        speech_array.append(processor(path, return_tensors=\"pt\").input_values)\n",
    "    return speech_array\n",
    "\n",
    "def map_to_transcription(batch):\n",
    "    return processor(batch, return_tensors=\"pt\").input_values\n",
    "\n",
    "speech_arrays = map_to_array(audio_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch, torchaudio\n",
    "\n",
    "# # get the arrays of the audio files\n",
    "\n",
    "# def speech_file_to_array_fn(batch):\n",
    "#     speech_array, sampling_rate = torchaudio.load(batch)    # load the audio file\n",
    "#     resampler = torchaudio.transforms.Resample(sampling_rate, 16_000)   # resample the audio file\n",
    "#     batch = resampler(speech_array).squeeze().numpy()   # squeeze the audio file\n",
    "#     return batch\n",
    "   \n",
    "# speech_arrays = [speech_file_to_array_fn(path) for path in audio_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "inputs = feature_extractor(speech_arrays, sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# tokenize the transcriptions to get the labels\n",
    "target = processor.tokenizer(transcriptions_paths, return_tensors=\"pt\", padding=True).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([300, 163200]), torch.Size([300, 120]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"input_values\"].shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "common_voice_dataset = Dataset.from_dict({\"input_values\": inputs[\"input_values\"], \"labels\": target})\n",
    "\n",
    "# split the dataset into training and validation datasets\n",
    "\n",
    "common_voice_dataset = common_voice_dataset.train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_values', 'labels'],\n",
       "        num_rows: 240\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_values', 'labels'],\n",
       "        num_rows: 60\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': [0.0002115588285960257,\n",
       "  0.0002115588285960257,\n",
       "  0.0002115588285960257,\n",
       "  0.0002115588285960257,\n",
       "  0.0002115588285960257,\n",
       "  0.0002115588285960257,\n",
       "  0.00021155879949219525,\n",
       "  0.0002115588722517714,\n",
       "  0.0002115588285960257,\n",
       "  0.0002115587703883648,\n",
       "  0.0002115586248692125,\n",
       "  0.00021155865397304296,\n",
       "  0.0002115586685249582,\n",
       "  0.00021155847935006022,\n",
       "  0.00021155922149773687,\n",
       "  0.00021155900321900845,\n",
       "  0.00021155989088583738,\n",
       "  0.00021155884314794093,\n",
       "  0.00021155983267817646,\n",
       "  0.00021155763533897698,\n",
       "  0.00021155891590751708,\n",
       "  0.00021155792637728155,\n",
       "  0.0002115573443006724,\n",
       "  0.00021155792637728155,\n",
       "  0.00021155792637728155,\n",
       "  0.0002115595416398719,\n",
       "  0.0002115588285960257,\n",
       "  0.0002115594397764653,\n",
       "  0.00021155991998966783,\n",
       "  0.0002115566749125719,\n",
       "  0.00021155801368877292,\n",
       "  0.00021155711147002876,\n",
       "  0.0002115562674589455,\n",
       "  0.00021156568254809827,\n",
       "  0.00021155459398869425,\n",
       "  0.00021156603179406375,\n",
       "  0.00021155360445845872,\n",
       "  0.0002115698589477688,\n",
       "  0.0002115623647114262,\n",
       "  0.00021156451839488,\n",
       "  0.00021156090951990336,\n",
       "  0.00021155558351892978,\n",
       "  0.0002115707320626825,\n",
       "  0.00021153160196263343,\n",
       "  0.00021155471040401608,\n",
       "  0.0002115474344464019,\n",
       "  0.0002115600073011592,\n",
       "  0.00021156978618819267,\n",
       "  0.00021156494040042162,\n",
       "  0.000211571910767816,\n",
       "  0.0002115517418133095,\n",
       "  0.0002115268725901842,\n",
       "  0.00021155229478608817,\n",
       "  0.00021149535314179957,\n",
       "  0.00021162540360819548,\n",
       "  0.00021156352886464447,\n",
       "  0.00021159758034627885,\n",
       "  0.00021154862770345062,\n",
       "  0.00021156521688681096,\n",
       "  0.000211619510082528,\n",
       "  0.00021145744540262967,\n",
       "  0.0002116525429300964,\n",
       "  0.00021158234449103475,\n",
       "  0.00021176798327360302,\n",
       "  0.00021149191888980567,\n",
       "  0.0002115098905051127,\n",
       "  0.00021156854927539825,\n",
       "  0.00021143491903785616,\n",
       "  0.00021163959172554314,\n",
       "  0.00021164178906474262,\n",
       "  0.00021163694327697158,\n",
       "  0.0002116349060088396,\n",
       "  0.00021145174105186015,\n",
       "  0.00021153243142180145,\n",
       "  0.0002110620989697054,\n",
       "  0.00021150078100617975,\n",
       "  0.00021190493134781718,\n",
       "  0.00021152952103875577,\n",
       "  0.00021186763478908688,\n",
       "  0.00021122934413142502,\n",
       "  0.00021240847127046436,\n",
       "  0.00021088197536300868,\n",
       "  0.00021196171292103827,\n",
       "  0.00021161317999940366,\n",
       "  0.00021256953186821193,\n",
       "  0.00021182416821829975,\n",
       "  0.00021064501197542995,\n",
       "  0.00021162313350941986,\n",
       "  0.00021061587904114276,\n",
       "  0.00021180708426982164,\n",
       "  0.00021196693705860525,\n",
       "  0.0002124314196407795,\n",
       "  0.00021215846936684102,\n",
       "  0.00021055729303043336,\n",
       "  0.00021240439673420042,\n",
       "  0.00021129261585883796,\n",
       "  0.00021152367116883397,\n",
       "  0.00021561044559348375,\n",
       "  0.00021460014977492392,\n",
       "  0.00021295525948517025,\n",
       "  0.00020670500816777349,\n",
       "  0.00021104728512000293,\n",
       "  0.0002112615475198254,\n",
       "  0.00020965433213859797,\n",
       "  0.0002136534167220816,\n",
       "  0.0002149225474568084,\n",
       "  0.00021367211593315005,\n",
       "  0.0002075519587378949,\n",
       "  0.0002103673614328727,\n",
       "  0.00021507267956621945,\n",
       "  0.00021157084847800434,\n",
       "  0.00021406778250820935,\n",
       "  0.00021355609351303428,\n",
       "  0.00021293904865160584,\n",
       "  0.00020875757036264986,\n",
       "  0.00021146604558452964,\n",
       "  0.00021375050710048527,\n",
       "  0.00021052548254374415,\n",
       "  0.00021298351930454373,\n",
       "  0.00021531178208533674,\n",
       "  0.00021184986690059304,\n",
       "  0.00021102129539940506,\n",
       "  0.0002177696005674079,\n",
       "  0.00021635083248838782,\n",
       "  0.00020458085054997355,\n",
       "  0.00021159948664717376,\n",
       "  0.0002167536149499938,\n",
       "  0.00021636566089000553,\n",
       "  0.00020223228784743696,\n",
       "  0.00022290158085525036,\n",
       "  0.00021788266894873232,\n",
       "  0.00021162134362384677,\n",
       "  0.00020653492538258433,\n",
       "  0.0002215706481365487,\n",
       "  0.0002198035508627072,\n",
       "  0.0002107104373862967,\n",
       "  0.00021919798746239394,\n",
       "  0.00021661350911017507,\n",
       "  0.00020497647346928716,\n",
       "  0.0002086875174427405,\n",
       "  0.00020928603771608323,\n",
       "  0.0002110467030433938,\n",
       "  0.00020271372341085225,\n",
       "  0.0002242183400085196,\n",
       "  0.00021691630536224693,\n",
       "  0.00020773331925738603,\n",
       "  0.00020630685321521014,\n",
       "  0.00021080748410895467,\n",
       "  0.00021484133321791887,\n",
       "  0.00021120924793649465,\n",
       "  0.00022246938897296786,\n",
       "  0.00021748417930211872,\n",
       "  0.00021999429736752063,\n",
       "  0.00021914990793447942,\n",
       "  0.00020042147662024945,\n",
       "  0.00020173666416667402,\n",
       "  0.00020364548254292458,\n",
       "  0.00021491495135705918,\n",
       "  0.00019239154062233865,\n",
       "  0.00020206955377943814,\n",
       "  0.00022410623205360025,\n",
       "  0.00021329874289222062,\n",
       "  0.00021408410975709558,\n",
       "  0.0002004440175369382,\n",
       "  0.0002214384003309533,\n",
       "  0.00019616207282524556,\n",
       "  0.0002046877780230716,\n",
       "  0.0002069219626719132,\n",
       "  0.00020819152996409684,\n",
       "  0.000209314443054609,\n",
       "  0.00020895445777568966,\n",
       "  0.00020997910178266466,\n",
       "  0.00021378914243541658,\n",
       "  0.00020804564701393247,\n",
       "  0.00022647075820714235,\n",
       "  0.00020716869039461017,\n",
       "  0.00021809535974171013,\n",
       "  0.00020753986609634012,\n",
       "  0.00021708746498916298,\n",
       "  0.00022280831763055176,\n",
       "  0.0002152029483113438,\n",
       "  0.00022253776842262596,\n",
       "  0.00021522441238630563,\n",
       "  0.0002157652488676831,\n",
       "  0.00021763952099718153,\n",
       "  0.00021434688824228942,\n",
       "  0.0002206288481829688,\n",
       "  0.00019667221931740642,\n",
       "  0.00020951344049535692,\n",
       "  0.0002147767663700506,\n",
       "  0.00020119769033044577,\n",
       "  0.00020929006859660149,\n",
       "  0.00021795163047499955,\n",
       "  0.00024043813755270094,\n",
       "  0.00019803663599304855,\n",
       "  0.00020415254402905703,\n",
       "  0.0002127879997715354,\n",
       "  0.0002041559637291357,\n",
       "  0.00019069603877142072,\n",
       "  0.00018308217113371938,\n",
       "  0.00020820829377043992,\n",
       "  0.00019730169151443988,\n",
       "  0.00022002379409968853,\n",
       "  0.00021467634360305965,\n",
       "  0.00021327740978449583,\n",
       "  0.00021633596043102443,\n",
       "  0.00021333267795853317,\n",
       "  0.0002021110849454999,\n",
       "  0.0001892984437290579,\n",
       "  0.0002227805380243808,\n",
       "  0.00022409793746192008,\n",
       "  0.00020503997802734375,\n",
       "  0.00021165674843359739,\n",
       "  0.00020785418746527284,\n",
       "  0.00020134368969593197,\n",
       "  0.0001864289224613458,\n",
       "  0.00020768858666997403,\n",
       "  0.00020501052495092154,\n",
       "  0.0001917099580168724,\n",
       "  0.00022752844961360097,\n",
       "  0.00021303055109456182,\n",
       "  0.00020217301789671183,\n",
       "  0.0001916027977131307,\n",
       "  0.00023147574393078685,\n",
       "  0.00022123240341898054,\n",
       "  0.0001922558731166646,\n",
       "  0.0002204744378104806,\n",
       "  0.00022175646154209971,\n",
       "  0.00021086189371999353,\n",
       "  0.00018698848725762218,\n",
       "  0.00021699242643080652,\n",
       "  0.00021916483819950372,\n",
       "  0.00020895722263958305,\n",
       "  0.00021168214152567089,\n",
       "  0.00021432341600302607,\n",
       "  0.00021649542031809688,\n",
       "  0.00021076749544590712,\n",
       "  0.00022351846564561129,\n",
       "  0.00020207058696541935,\n",
       "  0.00020649774523917586,\n",
       "  0.00020390508871059865,\n",
       "  0.0002144738391507417,\n",
       "  0.00020655401749536395,\n",
       "  0.00021950583322905004,\n",
       "  0.0002274686557939276,\n",
       "  0.0002067249151878059,\n",
       "  0.00019443912606220692,\n",
       "  0.0002132139925379306,\n",
       "  0.00021785056742373854,\n",
       "  0.00022281150449998677,\n",
       "  0.00020980299450457096,\n",
       "  0.0002268537791678682,\n",
       "  0.0001977387146325782,\n",
       "  0.0001838229363784194,\n",
       "  0.0001992789766518399,\n",
       "  0.0002129712956957519,\n",
       "  0.0002250971447210759,\n",
       "  0.0002153314126189798,\n",
       "  0.00022462118067778647,\n",
       "  0.00021575433493126184,\n",
       "  0.00020523655985016376,\n",
       "  0.00021790823666378856,\n",
       "  0.00021478475537151098,\n",
       "  0.00021692697191610932,\n",
       "  0.00022554061433766037,\n",
       "  0.00021798278612550348,\n",
       "  0.0002160651929443702,\n",
       "  0.00019329672795720398,\n",
       "  0.0002206804056186229,\n",
       "  0.00020590907661244273,\n",
       "  0.00020826236868742853,\n",
       "  0.00021886736794840544,\n",
       "  0.00023227163183037192,\n",
       "  0.0002325719251530245,\n",
       "  0.0002155339898308739,\n",
       "  0.00023099985264707357,\n",
       "  0.00021972222020849586,\n",
       "  0.0002208061923738569,\n",
       "  0.00021261931397020817,\n",
       "  0.000230531208217144,\n",
       "  0.00021786375145893544,\n",
       "  0.0002124150632880628,\n",
       "  0.00020492328621912748,\n",
       "  0.00020498792582657188,\n",
       "  0.00021549529628828168,\n",
       "  0.00021477497648447752,\n",
       "  0.0002296085876878351,\n",
       "  0.00021167538943700492,\n",
       "  0.0002195210981881246,\n",
       "  0.00023169726773630828,\n",
       "  0.00023920215608086437,\n",
       "  0.000214801388210617,\n",
       "  0.000192677864106372,\n",
       "  0.0001927488046931103,\n",
       "  0.00020072072220500559,\n",
       "  0.00020835932809859514,\n",
       "  0.00026080457610078156,\n",
       "  0.00026803804212249815,\n",
       "  0.00022363824245985597,\n",
       "  0.00022260287369135767,\n",
       "  0.0002964897721540183,\n",
       "  0.0003436098340898752,\n",
       "  0.00023578661784995347,\n",
       "  0.00016851506370585412,\n",
       "  0.00012652926670853049,\n",
       "  0.0001522299280622974,\n",
       "  0.0002170478692278266,\n",
       "  0.00039070536149665713,\n",
       "  0.0004422837228048593,\n",
       "  0.0003745366702787578,\n",
       "  0.0003162075881846249,\n",
       "  0.0003937956062145531,\n",
       "  0.00037715453072451055,\n",
       "  0.000264073780272156,\n",
       "  0.0001528838329249993,\n",
       "  0.000147094382555224,\n",
       "  0.00022403994807973504,\n",
       "  0.00035718356957659125,\n",
       "  0.0004150092718191445,\n",
       "  0.00039033222128637135,\n",
       "  0.0004813642881345004,\n",
       "  0.0007938643684610724,\n",
       "  0.0009501097374595702,\n",
       "  0.0006625159876421094,\n",
       "  0.00010532691521802917,\n",
       "  -0.0004674448282457888,\n",
       "  -0.0006610025302506983,\n",
       "  -7.442357309628278e-05,\n",
       "  0.0011903120903298259,\n",
       "  0.0019855995196849108,\n",
       "  0.0015680869109928608,\n",
       "  0.0007871997659094632,\n",
       "  0.0006820309208706021,\n",
       "  0.0009719028021208942,\n",
       "  0.000987515551969409,\n",
       "  0.00037352475919760764,\n",
       "  -0.00014022008690517396,\n",
       "  -0.0002711045672185719,\n",
       "  0.0008346698596142232,\n",
       "  0.002042453270405531,\n",
       "  0.002363593550398946,\n",
       "  0.002412377158179879,\n",
       "  0.0037994736339896917,\n",
       "  0.00506350863724947,\n",
       "  0.0029754918068647385,\n",
       "  -0.002132483758032322,\n",
       "  -0.005378322210162878,\n",
       "  -0.004033489152789116,\n",
       "  0.0007893542642705142,\n",
       "  0.005558387842029333,\n",
       "  0.007638565730303526,\n",
       "  0.006106891669332981,\n",
       "  0.0030619921162724495,\n",
       "  0.0005133966915309429,\n",
       "  -0.0014674450503662229,\n",
       "  -0.0032623482402414083,\n",
       "  -0.0029822438955307007,\n",
       "  -0.0002072392380796373,\n",
       "  0.0014990965137258172,\n",
       "  -0.0012669709976762533,\n",
       "  -0.006407552864402533,\n",
       "  -0.007664498873054981,\n",
       "  -0.001999904867261648,\n",
       "  0.008063321933150291,\n",
       "  0.013652782887220383,\n",
       "  0.01174609549343586,\n",
       "  0.0027943316381424665,\n",
       "  -0.007444536779075861,\n",
       "  -0.01447652094066143,\n",
       "  -0.0186291690915823,\n",
       "  -0.01622498594224453,\n",
       "  -0.008252497762441635,\n",
       "  0.002471506129950285,\n",
       "  0.011792724952101707,\n",
       "  0.009705234318971634,\n",
       "  0.00047962242388166487,\n",
       "  -0.009802356362342834,\n",
       "  -0.010384085588157177,\n",
       "  -0.0031936848536133766,\n",
       "  0.0010143358958885074,\n",
       "  -0.002297535538673401,\n",
       "  -0.010799621231853962,\n",
       "  -0.012544219382107258,\n",
       "  -0.011693455278873444,\n",
       "  -0.00853891484439373,\n",
       "  -0.008913960307836533,\n",
       "  -0.008723622187972069,\n",
       "  -2.6039519980258774e-06,\n",
       "  0.006389714311808348,\n",
       "  0.006832316983491182,\n",
       "  -0.0067938268184661865,\n",
       "  -0.020102210342884064,\n",
       "  -0.014802523888647556,\n",
       "  -0.018754251301288605,\n",
       "  -0.007796396967023611,\n",
       "  -0.007824094966053963,\n",
       "  -0.00633771950379014,\n",
       "  -0.006843629293143749,\n",
       "  -0.005226294044405222,\n",
       "  0.004735681228339672,\n",
       "  -0.0011302027851343155,\n",
       "  -0.009681912139058113,\n",
       "  -0.02150076813995838,\n",
       "  -0.008993172086775303,\n",
       "  -0.0017953886417672038,\n",
       "  -0.013447647914290428,\n",
       "  -0.007363854441791773,\n",
       "  -0.021407058462500572,\n",
       "  0.03482320159673691,\n",
       "  0.010164790786802769,\n",
       "  -0.003103893715888262,\n",
       "  -0.006325315218418837,\n",
       "  -0.005067301448434591,\n",
       "  0.010268370620906353,\n",
       "  0.006529728416353464,\n",
       "  0.017914222553372383,\n",
       "  -0.00014502259728033096,\n",
       "  -0.014441370964050293,\n",
       "  -0.0006651520379818976,\n",
       "  -0.022145433351397514,\n",
       "  0.01783982291817665,\n",
       "  0.006314508616924286,\n",
       "  -0.000926620268728584,\n",
       "  -0.03202158957719803,\n",
       "  -0.027330931276082993,\n",
       "  0.008878208696842194,\n",
       "  -0.0029711073730140924,\n",
       "  -0.015308625996112823,\n",
       "  0.009608619846403599,\n",
       "  -0.01701354794204235,\n",
       "  -0.0734923705458641,\n",
       "  -0.049417849630117416,\n",
       "  0.0118910176679492,\n",
       "  0.02341318316757679,\n",
       "  -0.0019258238608017564,\n",
       "  -0.02633660100400448,\n",
       "  0.0780997946858406,\n",
       "  0.0565304234623909,\n",
       "  0.029489317908883095,\n",
       "  0.03274111449718475,\n",
       "  0.05994269624352455,\n",
       "  0.024205662310123444,\n",
       "  0.049105871468782425,\n",
       "  0.02007298730313778,\n",
       "  0.020800866186618805,\n",
       "  -0.006022594403475523,\n",
       "  -0.02199547179043293,\n",
       "  0.026637589558959007,\n",
       "  0.013612507842481136,\n",
       "  0.0936615914106369,\n",
       "  0.08675796538591385,\n",
       "  0.05607118830084801,\n",
       "  0.07793354243040085,\n",
       "  0.0919622927904129,\n",
       "  0.09381785243749619,\n",
       "  0.16657955944538116,\n",
       "  0.22431109845638275,\n",
       "  0.2665726840496063,\n",
       "  0.2846054434776306,\n",
       "  0.25126099586486816,\n",
       "  0.16977354884147644,\n",
       "  0.21620269119739532,\n",
       "  0.20355917513370514,\n",
       "  0.15980997681617737,\n",
       "  0.1568811684846878,\n",
       "  0.1404448002576828,\n",
       "  0.1344168484210968,\n",
       "  0.16306763887405396,\n",
       "  0.15852530300617218,\n",
       "  0.0757446363568306,\n",
       "  0.19669201970100403,\n",
       "  -0.03489962965250015,\n",
       "  0.9439588785171509,\n",
       "  2.4370453357696533,\n",
       "  1.9708832502365112,\n",
       "  1.881972312927246,\n",
       "  1.7412775754928589,\n",
       "  1.7713230848312378,\n",
       "  1.7999500036239624,\n",
       "  1.8637547492980957,\n",
       "  1.9017279148101807,\n",
       "  1.730425477027893,\n",
       "  1.6489421129226685,\n",
       "  1.408815622329712,\n",
       "  1.255295991897583,\n",
       "  1.1928315162658691,\n",
       "  1.0204933881759644,\n",
       "  1.125266671180725,\n",
       "  1.2990001440048218,\n",
       "  1.3927656412124634,\n",
       "  1.6899182796478271,\n",
       "  1.8774468898773193,\n",
       "  2.134655714035034,\n",
       "  2.3842930793762207,\n",
       "  2.523644208908081,\n",
       "  2.591799020767212,\n",
       "  2.594204902648926,\n",
       "  2.647068738937378,\n",
       "  2.668976068496704,\n",
       "  2.616490125656128,\n",
       "  2.7184600830078125,\n",
       "  2.747349739074707,\n",
       "  2.708059072494507,\n",
       "  2.773871898651123,\n",
       "  2.6529340744018555,\n",
       "  2.559988021850586,\n",
       "  2.5078201293945312,\n",
       "  2.363258123397827,\n",
       "  2.183567523956299,\n",
       "  1.9991284608840942,\n",
       "  1.7411141395568848,\n",
       "  1.4809720516204834,\n",
       "  1.1540433168411255,\n",
       "  0.8007416725158691,\n",
       "  0.5002579092979431,\n",
       "  0.18763494491577148,\n",
       "  -0.1793975681066513,\n",
       "  -0.46500515937805176,\n",
       "  -0.8241310715675354,\n",
       "  -1.119582176208496,\n",
       "  -1.4498021602630615,\n",
       "  -1.7636052370071411,\n",
       "  -2.104419708251953,\n",
       "  -2.4180665016174316,\n",
       "  -2.7723801136016846,\n",
       "  -3.1097779273986816,\n",
       "  -3.4483845233917236,\n",
       "  -3.725698709487915,\n",
       "  -3.9719748497009277,\n",
       "  -4.224518299102783,\n",
       "  -4.305046558380127,\n",
       "  -4.381418704986572,\n",
       "  -4.410826206207275,\n",
       "  -4.381600379943848,\n",
       "  -4.452838897705078,\n",
       "  -4.38911247253418,\n",
       "  -4.388318061828613,\n",
       "  -4.4045515060424805,\n",
       "  -4.399410247802734,\n",
       "  -4.400843620300293,\n",
       "  -4.376126766204834,\n",
       "  -4.316718101501465,\n",
       "  -4.172597408294678,\n",
       "  -3.9002506732940674,\n",
       "  -3.706557512283325,\n",
       "  -3.4262313842773438,\n",
       "  -3.043354034423828,\n",
       "  -2.6665873527526855,\n",
       "  -2.298677444458008,\n",
       "  -1.8948811292648315,\n",
       "  -1.493585228919983,\n",
       "  -1.1017332077026367,\n",
       "  -0.682330310344696,\n",
       "  -0.31862059235572815,\n",
       "  0.08052155375480652,\n",
       "  0.4227372407913208,\n",
       "  0.710261881351471,\n",
       "  1.0171107053756714,\n",
       "  1.2760053873062134,\n",
       "  1.486286997795105,\n",
       "  1.715447187423706,\n",
       "  1.9524812698364258,\n",
       "  2.092241048812866,\n",
       "  2.197611093521118,\n",
       "  2.298612117767334,\n",
       "  2.3384413719177246,\n",
       "  2.364945650100708,\n",
       "  2.4106109142303467,\n",
       "  2.391896963119507,\n",
       "  2.37138032913208,\n",
       "  2.328016757965088,\n",
       "  2.2297470569610596,\n",
       "  2.1574113368988037,\n",
       "  2.0747506618499756,\n",
       "  1.9524234533309937,\n",
       "  1.9120384454727173,\n",
       "  1.8322941064834595,\n",
       "  1.7226688861846924,\n",
       "  1.6605242490768433,\n",
       "  1.5102475881576538,\n",
       "  1.4187616109848022,\n",
       "  1.2808982133865356,\n",
       "  1.0604312419891357,\n",
       "  0.961399257183075,\n",
       "  0.7365404367446899,\n",
       "  0.547232985496521,\n",
       "  0.4270375967025757,\n",
       "  0.24331626296043396,\n",
       "  0.15000970661640167,\n",
       "  0.1371825486421585,\n",
       "  0.07051892578601837,\n",
       "  0.09985963255167007,\n",
       "  0.1769915223121643,\n",
       "  0.21809819340705872,\n",
       "  0.33474472165107727,\n",
       "  0.4385825991630554,\n",
       "  0.5466415286064148,\n",
       "  0.6545630693435669,\n",
       "  0.79462069272995,\n",
       "  0.9691365361213684,\n",
       "  1.0990417003631592,\n",
       "  1.3000237941741943,\n",
       "  1.4559353590011597,\n",
       "  1.5187078714370728,\n",
       "  1.6607340574264526,\n",
       "  1.6890052556991577,\n",
       "  1.691033124923706,\n",
       "  1.8128446340560913,\n",
       "  1.8209972381591797,\n",
       "  1.8737598657608032,\n",
       "  1.9795825481414795,\n",
       "  1.9423969984054565,\n",
       "  1.9182285070419312,\n",
       "  1.8397706747055054,\n",
       "  1.6380622386932373,\n",
       "  1.473663330078125,\n",
       "  1.2791749238967896,\n",
       "  1.0741188526153564,\n",
       "  0.9354532361030579,\n",
       "  0.8091949224472046,\n",
       "  0.657556414604187,\n",
       "  0.4909853935241699,\n",
       "  0.26581406593322754,\n",
       "  -0.010656830854713917,\n",
       "  -0.31812983751296997,\n",
       "  -0.6287669539451599,\n",
       "  -0.9476788640022278,\n",
       "  -1.2656898498535156,\n",
       "  -1.5174719095230103,\n",
       "  -1.8005189895629883,\n",
       "  -2.042252540588379,\n",
       "  -2.275742292404175,\n",
       "  -2.502880811691284,\n",
       "  -2.6986937522888184,\n",
       "  -2.859901189804077,\n",
       "  -3.0376505851745605,\n",
       "  -3.2263145446777344,\n",
       "  -3.3983771800994873,\n",
       "  -3.5801212787628174,\n",
       "  -3.7537200450897217,\n",
       "  -3.8758912086486816,\n",
       "  -4.003159523010254,\n",
       "  -4.140981197357178,\n",
       "  -4.167919635772705,\n",
       "  -4.1653032302856445,\n",
       "  -4.112783432006836,\n",
       "  -3.9148404598236084,\n",
       "  -3.7366178035736084,\n",
       "  -3.541731595993042,\n",
       "  -3.1983819007873535,\n",
       "  -2.915950298309326,\n",
       "  -2.5517489910125732,\n",
       "  -2.1127445697784424,\n",
       "  -1.759278655052185,\n",
       "  -1.3794907331466675,\n",
       "  -0.9438726902008057,\n",
       "  -0.6002151370048523,\n",
       "  -0.23573362827301025,\n",
       "  0.16692954301834106,\n",
       "  0.4575600028038025,\n",
       "  0.7781208157539368,\n",
       "  1.066781997680664,\n",
       "  1.293668270111084,\n",
       "  1.4934834241867065,\n",
       "  1.6864529848098755,\n",
       "  1.823118805885315,\n",
       "  1.890531063079834,\n",
       "  1.9681930541992188,\n",
       "  2.0246191024780273,\n",
       "  2.006411552429199,\n",
       "  2.0791242122650146,\n",
       "  2.096485137939453,\n",
       "  2.033355712890625,\n",
       "  2.057812213897705,\n",
       "  1.9800691604614258,\n",
       "  1.8525282144546509,\n",
       "  1.8353139162063599,\n",
       "  1.7361259460449219,\n",
       "  1.660400629043579,\n",
       "  1.6883562803268433,\n",
       "  1.546496033668518,\n",
       "  1.4311007261276245,\n",
       "  1.3605998754501343,\n",
       "  1.1625033617019653,\n",
       "  1.0724059343338013,\n",
       "  0.931472897529602,\n",
       "  0.6836578845977783,\n",
       "  0.5215007662773132,\n",
       "  0.28531399369239807,\n",
       "  0.07142159342765808,\n",
       "  -0.05356966704130173,\n",
       "  -0.1723768562078476,\n",
       "  -0.2612692415714264,\n",
       "  -0.29737159609794617,\n",
       "  -0.3837713897228241,\n",
       "  -0.48709338903427124,\n",
       "  -0.5375890135765076,\n",
       "  -0.6263505816459656,\n",
       "  -0.6150991320610046,\n",
       "  -0.5888279676437378,\n",
       "  -0.5269871950149536,\n",
       "  -0.37310412526130676,\n",
       "  -0.2723662555217743,\n",
       "  -0.06008775159716606,\n",
       "  0.07821587473154068,\n",
       "  0.21904079616069794,\n",
       "  0.4365743398666382,\n",
       "  0.5023670792579651,\n",
       "  0.6651933193206787,\n",
       "  0.7859970927238464,\n",
       "  0.8575467467308044,\n",
       "  0.9742883443832397,\n",
       "  1.0876537561416626,\n",
       "  1.2028371095657349,\n",
       "  1.3177695274353027,\n",
       "  1.4664616584777832,\n",
       "  1.5247066020965576,\n",
       "  1.5653775930404663,\n",
       "  1.585921287536621,\n",
       "  1.578102946281433,\n",
       "  1.591613531112671,\n",
       "  1.5987341403961182,\n",
       "  1.5954076051712036,\n",
       "  1.5616923570632935,\n",
       "  1.4922058582305908,\n",
       "  1.3444246053695679,\n",
       "  1.20191490650177,\n",
       "  1.027992844581604,\n",
       "  0.8326470851898193,\n",
       "  0.6125173568725586,\n",
       "  0.37173426151275635,\n",
       "  0.21856717765331268,\n",
       "  0.016726167872548103,\n",
       "  -0.1240566298365593,\n",
       "  -0.20411913096904755,\n",
       "  -0.3633357584476471,\n",
       "  -0.48979854583740234,\n",
       "  -0.682487428188324,\n",
       "  -0.9456902742385864,\n",
       "  -1.205969214439392,\n",
       "  -1.5706849098205566,\n",
       "  -1.8548680543899536,\n",
       "  -2.1071760654449463,\n",
       "  -2.379441261291504,\n",
       "  -2.539111614227295,\n",
       "  -2.699087142944336,\n",
       "  -2.7761523723602295,\n",
       "  -2.763845682144165,\n",
       "  -2.7649173736572266,\n",
       "  -2.7636938095092773,\n",
       "  -2.6867611408233643,\n",
       "  -2.6441495418548584,\n",
       "  -2.6034867763519287,\n",
       "  -2.4386792182922363,\n",
       "  -2.360687255859375,\n",
       "  -2.1704883575439453,\n",
       "  -1.884300708770752,\n",
       "  -1.7193539142608643,\n",
       "  -1.4364886283874512,\n",
       "  -1.1754341125488281,\n",
       "  -0.9515761137008667,\n",
       "  -0.6064685583114624,\n",
       "  -0.38325464725494385,\n",
       "  -0.08019430935382843,\n",
       "  0.16739699244499207,\n",
       "  0.2506975829601288,\n",
       "  0.4591146409511566,\n",
       "  0.5053959488868713,\n",
       "  0.5765020847320557,\n",
       "  0.6851889491081238,\n",
       "  0.6594050526618958,\n",
       "  0.7431766986846924,\n",
       "  0.8460610508918762,\n",
       "  0.898716390132904,\n",
       "  1.0306755304336548,\n",
       "  1.123719334602356,\n",
       "  1.114295244216919,\n",
       "  1.1387771368026733,\n",
       "  1.0913162231445312,\n",
       "  1.0490310192108154,\n",
       "  1.060054063796997,\n",
       "  1.0183027982711792,\n",
       "  1.0108174085617065,\n",
       "  1.003340244293213,\n",
       "  0.9213737845420837,\n",
       "  0.8563514947891235,\n",
       "  0.7561458945274353,\n",
       "  0.5672596096992493,\n",
       "  0.46923545002937317,\n",
       "  0.35883787274360657,\n",
       "  0.15089051425457,\n",
       "  0.07462570816278458,\n",
       "  -0.11623181402683258,\n",
       "  -0.2997235953807831,\n",
       "  -0.36826714873313904,\n",
       "  -0.5859301686286926,\n",
       "  -0.5751752853393555,\n",
       "  -0.6083089709281921,\n",
       "  -0.6558459997177124,\n",
       "  -0.5338632464408875,\n",
       "  -0.6913331747055054,\n",
       "  -0.6560109853744507,\n",
       "  -0.7096324563026428,\n",
       "  -0.8243927359580994,\n",
       "  -0.6449589133262634,\n",
       "  -0.6053266525268555,\n",
       "  -0.4618576467037201,\n",
       "  -0.3343871235847473,\n",
       "  -0.28910163044929504,\n",
       "  -0.30768343806266785,\n",
       "  -0.3112024664878845,\n",
       "  -0.35204556584358215,\n",
       "  -0.44192469120025635,\n",
       "  -0.35284119844436646,\n",
       "  -0.34862416982650757,\n",
       "  -0.20184385776519775,\n",
       "  0.0134127801284194,\n",
       "  0.14972969889640808,\n",
       "  0.3456699550151825,\n",
       "  0.4862174987792969,\n",
       "  0.6077651381492615,\n",
       "  0.6971328258514404,\n",
       "  0.7804784774780273,\n",
       "  0.8828733563423157,\n",
       "  0.9595599174499512,\n",
       "  0.9462765455245972,\n",
       "  0.9853324294090271,\n",
       "  1.0311707258224487,\n",
       "  0.997735321521759,\n",
       "  1.1136219501495361,\n",
       "  1.1102722883224487,\n",
       "  1.205788493156433,\n",
       "  1.2974262237548828,\n",
       "  1.2685253620147705,\n",
       "  1.394669532775879,\n",
       "  1.1903069019317627,\n",
       "  1.137316107749939,\n",
       "  1.0613045692443848,\n",
       "  0.8271425366401672,\n",
       "  0.8505974411964417,\n",
       "  0.6678536534309387,\n",
       "  0.5303788185119629,\n",
       "  0.4428514540195465,\n",
       "  0.2842949330806732,\n",
       "  0.18930554389953613,\n",
       "  0.08816248178482056,\n",
       "  0.021577337756752968,\n",
       "  -0.09129144251346588,\n",
       "  -0.1612423062324524,\n",
       "  -0.1789393573999405,\n",
       "  -0.2975011169910431,\n",
       "  -0.33626168966293335,\n",
       "  -0.3344200551509857,\n",
       "  -0.41200363636016846,\n",
       "  -0.4274017810821533,\n",
       "  -0.49543479084968567,\n",
       "  -0.5994196534156799,\n",
       "  -0.5477924346923828,\n",
       "  -0.5135913491249084,\n",
       "  -0.4897039532661438,\n",
       "  -0.3764108121395111,\n",
       "  -0.2610793113708496,\n",
       "  -0.2199374884366989,\n",
       "  -0.21890999376773834,\n",
       "  -0.12785838544368744,\n",
       "  -0.09646116942167282,\n",
       "  -0.07812317460775375,\n",
       "  -0.09229543805122375,\n",
       "  -0.15462933480739594,\n",
       "  -0.17285989224910736,\n",
       "  -0.2712385952472687,\n",
       "  -0.25654342770576477,\n",
       "  -0.2235710471868515,\n",
       "  -0.1946091651916504,\n",
       "  -0.08460542559623718,\n",
       "  -0.05290195345878601,\n",
       "  0.049268413335084915,\n",
       "  0.1011827290058136,\n",
       "  0.10928628593683243,\n",
       "  0.1490447074174881,\n",
       "  0.13195136189460754,\n",
       "  0.16396276652812958,\n",
       "  0.20648854970932007,\n",
       "  0.2349550575017929,\n",
       "  0.29562777280807495,\n",
       "  0.31463491916656494,\n",
       "  0.2574959993362427,\n",
       "  0.21349893510341644,\n",
       "  0.08096802234649658,\n",
       "  -0.04000244662165642,\n",
       "  -0.11075374484062195,\n",
       "  -0.26877161860466003,\n",
       "  -0.40607118606567383,\n",
       "  -0.5514354705810547,\n",
       "  -0.6390448808670044,\n",
       "  -0.7269094586372375,\n",
       "  -0.8193426728248596,\n",
       "  -0.8672836422920227,\n",
       "  -0.9948250651359558,\n",
       "  -1.0736562013626099,\n",
       "  -1.1580276489257812,\n",
       "  -1.2019429206848145,\n",
       "  -1.1685024499893188,\n",
       "  -1.131753921508789,\n",
       "  -1.074709177017212,\n",
       "  -1.0140715837478638,\n",
       "  -0.8984449505805969,\n",
       "  -0.8563317656517029,\n",
       "  -0.8409174084663391,\n",
       "  -0.7893491983413696,\n",
       "  -0.8148992657661438,\n",
       "  -0.8500003814697266,\n",
       "  -0.8288013935089111,\n",
       "  -0.8028611540794373,\n",
       "  -0.7566298246383667,\n",
       "  -0.6844748258590698,\n",
       "  -0.5993596911430359,\n",
       "  -0.5331109762191772,\n",
       "  -0.4642668664455414,\n",
       "  -0.4233292043209076,\n",
       "  -0.3889724016189575,\n",
       "  -0.3283301293849945,\n",
       "  -0.30176880955696106,\n",
       "  -0.18966305255889893,\n",
       "  -0.12830200791358948,\n",
       "  -0.036439236253499985,\n",
       "  0.06249088793992996,\n",
       "  0.08795549720525742,\n",
       "  0.23134222626686096,\n",
       "  0.26696231961250305,\n",
       "  0.2789067029953003,\n",
       "  0.39719444513320923,\n",
       "  0.4386642277240753,\n",
       "  0.5334872007369995,\n",
       "  0.6961343288421631,\n",
       "  0.7745925784111023,\n",
       "  0.8683717250823975,\n",
       "  0.874550998210907,\n",
       "  0.8366790413856506,\n",
       "  0.7978743314743042,\n",
       "  0.691742479801178,\n",
       "  0.65297931432724,\n",
       "  0.5980865359306335,\n",
       "  0.5409732460975647,\n",
       "  0.5610477924346924,\n",
       "  0.5229604244232178,\n",
       "  0.5350949764251709,\n",
       "  0.6457129120826721,\n",
       "  0.6982347369194031,\n",
       "  0.7865946888923645,\n",
       "  0.8248100876808167,\n",
       "  0.8148443102836609,\n",
       "  0.8051479458808899,\n",
       "  0.7702488303184509,\n",
       "  0.7238194346427917,\n",
       "  0.7088765501976013,\n",
       "  0.6833476424217224,\n",
       "  0.6828914880752563,\n",
       "  0.7425711154937744,\n",
       "  0.7373656034469604,\n",
       "  0.8330800533294678,\n",
       "  0.9369660019874573,\n",
       "  0.9733104109764099,\n",
       "  1.0624842643737793,\n",
       "  1.1138503551483154,\n",
       "  1.113539695739746,\n",
       "  1.2069010734558105,\n",
       "  1.137917160987854,\n",
       "  1.0644807815551758,\n",
       "  1.1053801774978638,\n",
       "  0.956372857093811,\n",
       "  0.9785755276679993,\n",
       "  0.9488229751586914,\n",
       "  0.8679424524307251,\n",
       "  0.9118330478668213,\n",
       "  0.8779431581497192,\n",
       "  0.9365136027336121,\n",
       "  0.8944681286811829,\n",
       "  0.8424587845802307,\n",
       "  0.7844565510749817,\n",
       "  0.6632863283157349,\n",
       "  0.6186970472335815,\n",
       "  0.5019271373748779,\n",
       "  0.3930971026420593,\n",
       "  0.26649007201194763,\n",
       "  0.11642173677682877,\n",
       "  0.053498364984989166,\n",
       "  -0.012209482491016388,\n",
       "  -0.09605684131383896,\n",
       "  -0.15029796957969666,\n",
       "  -0.2234693169593811,\n",
       "  -0.3627654016017914,\n",
       "  -0.507818877696991,\n",
       "  -0.6476168036460876,\n",
       "  -0.8177780508995056,\n",
       "  -0.9240971803665161,\n",
       "  -1.1074079275131226,\n",
       "  -1.2872116565704346,\n",
       "  -1.3972628116607666,\n",
       "  -1.482143521308899,\n",
       "  ...],\n",
       " 'labels': [31,\n",
       "  37,\n",
       "  29,\n",
       "  7,\n",
       "  25,\n",
       "  22,\n",
       "  8,\n",
       "  8,\n",
       "  23,\n",
       "  27,\n",
       "  8,\n",
       "  29,\n",
       "  26,\n",
       "  37,\n",
       "  31,\n",
       "  29,\n",
       "  4,\n",
       "  23,\n",
       "  15,\n",
       "  27,\n",
       "  31,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43,\n",
       "  43]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479ae17fd45f46afa8900d2866d2d6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluation metric\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = torch.argmax(pred_logits, dim=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "facebook/wav2vec2-large-xslr-53 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/facebook/wav2vec2-large-xslr-53/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    386\u001b[0m         path_or_repo_id,\n\u001b[1;32m    387\u001b[0m         filename,\n\u001b[1;32m    388\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    389\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    390\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    391\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    392\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    393\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    394\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    395\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    396\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    397\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1403\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1402\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1261\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1261\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1262\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1263\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1264\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1265\u001b[0m         timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1266\u001b[0m         library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[1;32m   1267\u001b[0m         library_version\u001b[38;5;241m=\u001b[39mlibrary_version,\n\u001b[1;32m   1268\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   1269\u001b[0m     )\n\u001b[1;32m   1270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1674\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1674\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1675\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1676\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   1677\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1678\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1679\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1680\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1681\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1682\u001b[0m )\n\u001b[1;32m   1683\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:369\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 369\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m    370\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[1;32m    371\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    372\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:393\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    392\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 393\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m     )\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-663e8b35-688fe0af17e7c6370d7e8f4f;c3dd1d3b-926a-406e-b708-e242f7caa81d)\n\nRepository Not Found for url: https://huggingface.co/facebook/wav2vec2-large-xslr-53/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train the model using the common_voice_dataset batch size of 8\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Wav2Vec2ForCTC\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m Wav2Vec2ForCTC\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook/wav2vec2-large-xslr-53\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     attention_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      8\u001b[0m     hidden_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      9\u001b[0m     feat_proj_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     10\u001b[0m     mask_time_prob\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m     11\u001b[0m     layerdrop\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     12\u001b[0m     ctc_loss_reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[1;32m     14\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(processor\u001b[38;5;241m.\u001b[39mtokenizer)\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mfreeze_feature_extractor()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/modeling_utils.py:2926\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2925\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 2926\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   2927\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m   2928\u001b[0m             CONFIG_NAME,\n\u001b[1;32m   2929\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   2930\u001b[0m             force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   2931\u001b[0m             resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m   2932\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   2933\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   2934\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   2935\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   2936\u001b[0m             subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   2937\u001b[0m             _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2938\u001b[0m             _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2939\u001b[0m         )\n\u001b[1;32m   2940\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2941\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/utils/hub.py:406\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: facebook/wav2vec2-large-xslr-53 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# train the model using the common_voice_dataset batch size of 8\n",
    "\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xslr-53\",\n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")\n",
    "\n",
    "model.freeze_feature_extractor()\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./wav2vec2-large-960h-turkish-demo\",\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    save_steps=400,\n",
    "    eval_steps=400,\n",
    "    logging_steps=400,\n",
    "    learning_rate=3e-4,\n",
    "    warmup_steps=500,\n",
    "    save_total_limit=2,\n",
    "    )\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=processor.data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_dataset[\"train\"],\n",
    "    eval_dataset=common_voice_dataset[\"test\"],\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/hwanghaeeul/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5754de75ae427da3ef40450854b21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: command buffer exited with error status.\n",
      "\tThe Metal Performance Shaders operations encoded on it may not have completed.\n",
      "\tError: \n",
      "\t(null)\n",
      "\tInsufficient Memory (00000008:kIOGPUCommandBufferCallbackErrorOutOfMemory)\n",
      "\t<AGXG13GFamilyCommandBuffer: 0x314dddf00>\n",
      "    label = <none> \n",
      "    device = <AGXG13GDevice: 0x13cdc2000>\n",
      "        name = Apple M1 \n",
      "    commandQueue = <AGXG13GFamilyCommandQueue: 0x16b6ff400>\n",
      "        label = <none> \n",
      "        device = <AGXG13GDevice: 0x13cdc2000>\n",
      "            name = Apple M1 \n",
      "    retainedReferences = 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.02 GB, other allocations: 2.38 MB, max allowed: 9.07 GB). Tried to allocate 1.99 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 42\u001b[0m\n\u001b[1;32m     32\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     33\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     34\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mprocessor\u001b[38;5;241m.\u001b[39mfeature_extractor,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1540\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1541\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1542\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1543\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1544\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2772\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2772\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2775\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2795\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2794\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2795\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   2796\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1968\u001b[0m, in \u001b[0;36mWav2Vec2ForCTC.forward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, target_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;124;03m    Labels for connectionist temporal classification. Note that `target_length` has to be smaller or equal to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;124;03m    config.vocab_size - 1]`.\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1968\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwav2vec2(\n\u001b[1;32m   1969\u001b[0m     input_values,\n\u001b[1;32m   1970\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1971\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1972\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1973\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1974\u001b[0m )\n\u001b[1;32m   1976\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1977\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1553\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1548\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1549\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1550\u001b[0m )\n\u001b[1;32m   1551\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1553\u001b[0m extract_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(input_values)\n\u001b[1;32m   1554\u001b[0m extract_features \u001b[38;5;241m=\u001b[39m extract_features\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# compute reduced attention_mask corresponding to feature vectors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:460\u001b[0m, in \u001b[0;36mWav2Vec2FeatureEncoder.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    455\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    456\u001b[0m             conv_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    457\u001b[0m             hidden_states,\n\u001b[1;32m    458\u001b[0m         )\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m conv_layer(hidden_states)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:338\u001b[0m, in \u001b[0;36mWav2Vec2LayerNormConvLayer.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    335\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(hidden_states)\n\u001b[1;32m    337\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 338\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m    339\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    341\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(hidden_states)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlayer_norm(\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalized_shape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2575\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2573\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2574\u001b[0m     )\n\u001b[0;32m-> 2575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlayer_norm(\u001b[38;5;28minput\u001b[39m, normalized_shape, weight, bias, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 8.02 GB, other allocations: 2.38 MB, max allowed: 9.07 GB). Tried to allocate 1.99 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC, TrainingArguments, Trainer\n",
    "\n",
    "# 모델 설정\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\",\n",
    "    ctc_loss_reduction=\"mean\",\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(vocab_dict)\n",
    ")\n",
    "\n",
    "# 학습 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./wav2vec2-finetuned\",\n",
    "    per_device_train_batch_size=32,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=10,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    logging_steps=500,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.005,\n",
    "    warmup_steps=1000,\n",
    ")\n",
    "\n",
    "# 손실 함수 설정\n",
    "ctc_loss = torch.nn.CTCLoss()\n",
    "\n",
    "# 옵티마이저 설정\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=training_args.learning_rate)\n",
    "\n",
    "# Trainer 객체 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_dataset[\"train\"],\n",
    "    eval_dataset=common_voice_dataset[\"test\"],\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
